# Prompt runner v1

The prompt runner is a simple application running on a runpod pod that:
- Queues API-ready prompts in local comfyui (using websockets)
- Waits for prompts to ends to reads prompts outputs
- Save files in google storage
- When all prompt ends, it terminates the runpod machine

It also changes the prompt json file for experimentation:
- Changes the positive prompts based on auxiliary text files
- Changes values such as lora strenghts, steps, etc
- Which Loras are active

Prompt runner is made by me for me. It will never be shared or exposed online
I send this prompt-runner to the workstations I want it to run and it just works.

# Prompt runner v2

Version 2 will support a new, more complex, workflow based in Wan2.2.
Wan2.2, different than wan2.1, has a 2-pass sampling system: first you pass with a High Noise model, then with a low noise model.
Because of memory limitations, we will split this system in 2 different prompts, but both of them are based in the same file (prompt.json).
There is a 3rd, final step, which is to upscale and combine all video files. That's the combine.json.

## Logic
- Read the folder prompt_files. Each file in the folder will have the following properties, separated by an empty line:
	- The load video name
	- The number of frames to render at each pass
	- the positive prompt
	- the negative prompt

- RENDER logic: The system will then create a "job".
	- First job - HIGH CONFIGURATIONS:
		- Using the high model and the high lora
		- NOT loading a reference image
		- Saving the latent after the Sampling
	- Second Job - LOW CONFIGURATION: 
		- Using the low model and the low lora
		- NOT loading reference image
		- loading latests FOR the ksampler
		- saving the output video and the frame number LENGTH-10, LENGTH being the number of frames rendered.
	- Third job - HIGH CONFIGURATIONS:
		- Using the high model and the high lora
		- loading a reference image created in the second job
		- Advancing the skip-n-frames of the reference video by LENGTH
		- Saving the latent after the Sampling
	- Fourth Job - LOW CONFIGURATION: 
		- Same as second
	- The process repeats until the number of frames to render are out, so all frames are rendered.

- UPSCALE-AND-COMBINE logic: Then we will combine all videos using the involves de combine.json prompt
	- First job: - Does the whole process, loading the first video (generated by render job 2)
		- Saves the output file
	- Second job:
		- Does the whole process, loading the second video (generated by render job 4)
		- Loads the file of the first combined job 
		- Combines the generated video with the first video of the first job
	- Third job:
		- Does the whole process, loading the third video (generated by render job 6)
		- Loads the file of the second combined job 
		- Combines the generated video with the first video of the second job, which now has the combined video of render jobs 2, 4 an 6, all upscaled and combined into one single file
	- proceeds until everything is merged
	
- Uploads combined file to Google storage
- Delete all files (latents and genrated videos) from local server


### Logic Detailing:
- The jobs for one prompt file could be theoretically all created when the system is initialized, but every even job starting for step 3 needs the last generated image, so variables from previous completed job needs to be inputed in the new job.
- Both render jobs are actually the same prompt with a few differences:
	- node 309:298, lora:
		- High: wan2.2_high_t2v.safetensors
		- Low: wan2.2_low_t2v.safetensors
	- node 4, model:
		- High:Wan2.2_HIGH_Low_Noise_14B_VACE-Q8_0.gguf
		- Low: Wan2.2_T2V_Low_Noise_14B_VACE-Q8_0.gguf
	- node 144, ref_images:
		- This json part should be deleted from the first and second render job
	- node 54, samples:
		- High: this json part should be deleted from every HIGH render job 
	- node 365, latent:
		- LOW: this json part should be deleted from every LOW render job 
	- node 341, samples:
		- High: this json part should be deleted from every High render job 	
	
Desired python variables:
	- FRAMES-TO-RENDER: the number of frames to render	
	
Similar logic:
	- node 19, inputs, value: 
		- Render job 1 and 2: FRAMES-TO-RENDER
		- Render job 3 and 4: FRAMES-TO-RENDER
		- repeat above for being
	- Node 348, start frame:
		- Render job 1 and 2: 0
		- Render job 3 and 4: FRAMES-TO-RENDER-10
		- repeat above for being
	
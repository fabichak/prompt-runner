{
  "6": {
    "inputs": {
      "text": "The image is a portrait of a young OFA1M1-clothed with blonde hair and cat ears on her head. She is wearing a white bikini and matching panties. She has a big smile on her face and is posing with both arms open. The background is a plain white wall. The overall mood of the image is playful and provocative. she has no tattoos. She is dancing.",
      "clip": [
        "12",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "7": {
    "inputs": {
      "text": "è‰²è°ƒè‰³ä¸½ï¼Œè¿‡æ›ï¼Œé™æ€ï¼Œç»†èŠ‚æ¨¡ç³Šä¸æ¸…ï¼Œå­—å¹•ï¼Œé£æ ¼ï¼Œä½œå“ï¼Œç”»ä½œï¼Œç”»é¢ï¼Œé™æ­¢ï¼Œæ•´ä½“å‘ç°ï¼Œæœ€å·®è´¨é‡ï¼Œä½è´¨é‡ï¼ŒJPEGå‹ç¼©æ®‹ç•™ï¼Œä¸‘é™‹çš„ï¼Œæ®‹ç¼ºçš„ï¼Œå¤šä½™çš„æ‰‹æŒ‡ï¼Œç”»å¾—ä¸å¥½çš„æ‰‹éƒ¨ï¼Œç”»å¾—ä¸å¥½çš„è„¸éƒ¨ï¼Œç•¸å½¢çš„ï¼Œæ¯å®¹çš„ï¼Œå½¢æ€ç•¸å½¢çš„è‚¢ä½“ï¼Œæ‰‹æŒ‡èåˆï¼Œé™æ­¢ä¸åŠ¨çš„ç”»é¢ï¼Œæ‚ä¹±çš„èƒŒæ™¯ï¼Œä¸‰æ¡è…¿ï¼ŒèƒŒæ™¯äººå¾ˆå¤šï¼Œå€’ç€èµ°",
      "clip": [
        "12",
        0
      ]
    },
    "class_type": "CLIPTextEncode",
    "_meta": {
      "title": "CLIP Text Encode (Prompt)"
    }
  },
  "12": {
    "inputs": {
      "clip_name": "split_files/text_encoders/umt5_xxl_fp16.safetensors",
      "type": "wan",
      "device": "default"
    },
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    }
  },
  "13": {
    "inputs": {
      "vae_name": "Wan2_1_VAE_fp32.safetensors"
    },
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    }
  },
  "17": {
    "inputs": {
      "video": "4.mp4",
      "force_rate": 0,
      "custom_width": 0,
      "custom_height": 0,
      "frame_load_cap": 0,
      "skip_first_frames": 0,
      "select_every_nth": 1,
      "format": "AnimateDiff"
    },
    "class_type": "VHS_LoadVideo",
    "_meta": {
      "title": "Load Video (Upload) ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "22": {
    "inputs": {
      "x": 0,
      "y": 0,
      "resize_source": false,
      "destination": [
        "23",
        0
      ],
      "source": [
        "115",
        0
      ],
      "mask": [
        "27",
        0
      ]
    },
    "class_type": "ImageCompositeMasked",
    "_meta": {
      "title": "ImageCompositeMasked"
    }
  },
  "23": {
    "inputs": {
      "width": [
        "90",
        0
      ],
      "height": [
        "91",
        0
      ],
      "batch_size": [
        "17",
        1
      ],
      "color": 16777215
    },
    "class_type": "EmptyImage",
    "_meta": {
      "title": "EmptyImage"
    }
  },
  "24": {
    "inputs": {
      "image": "4.png"
    },
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Image"
    }
  },
  "27": {
    "inputs": {
      "value": 0.20000000000000004,
      "width": [
        "90",
        0
      ],
      "height": [
        "91",
        0
      ]
    },
    "class_type": "SolidMask",
    "_meta": {
      "title": "SolidMask"
    }
  },
  "38": {
    "inputs": {
      "frame_rate": 30,
      "loop_count": 0,
      "filename_prefix": "ControlPreview",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 19,
      "save_metadata": false,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": false,
      "images": [
        "116",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "60": {
    "inputs": {
      "shift": 8,
      "model": [
        "89",
        0
      ]
    },
    "class_type": "ModelSamplingSD3",
    "_meta": {
      "title": "ModelSamplingSD3"
    }
  },
  "78": {
    "inputs": {
      "frame_rate": 30,
      "loop_count": 0,
      "filename_prefix": "bbaudio/SuperUltimateVACEUpscale",
      "format": "video/h264-mp4",
      "pix_fmt": "yuv420p",
      "crf": 0,
      "save_metadata": true,
      "trim_to_audio": false,
      "pingpong": false,
      "save_output": true,
      "images": [
        "104",
        0
      ]
    },
    "class_type": "VHS_VideoCombine",
    "_meta": {
      "title": "Video Combine ğŸ¥ğŸ…¥ğŸ…—ğŸ…¢"
    }
  },
  "80": {
    "inputs": {
      "ckpt_name": "depth_anything_v2_vitl.pth",
      "resolution": [
        "90",
        0
      ],
      "image": [
        "114",
        0
      ]
    },
    "class_type": "DepthAnythingV2Preprocessor",
    "_meta": {
      "title": "Depth Anything V2 - Relative"
    }
  },
  "84": {
    "inputs": {
      "coarse": "disable",
      "resolution": [
        "91",
        0
      ],
      "image": [
        "115",
        0
      ]
    },
    "class_type": "LineArtPreprocessor",
    "_meta": {
      "title": "Realistic Lineart"
    }
  },
  "85": {
    "inputs": {
      "image": [
        "84",
        0
      ]
    },
    "class_type": "ImageInvert",
    "_meta": {
      "title": "Invert Image"
    }
  },
  "86": {
    "inputs": {
      "sharpen_radius": 1,
      "sigma": 10,
      "alpha": 0.10000000000000002,
      "image": [
        "85",
        0
      ]
    },
    "class_type": "ImageSharpen",
    "_meta": {
      "title": "Image Sharpen"
    }
  },
  "89": {
    "inputs": {
      "sage_attention": "sageattn_qk_int8_pv_fp16_triton",
      "model": [
        "121",
        0
      ]
    },
    "class_type": "PathchSageAttentionKJ",
    "_meta": {
      "title": "Patch Sage Attention KJ"
    }
  },
  "90": {
    "inputs": {
      "value": 720
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "Width Upscale"
    }
  },
  "91": {
    "inputs": {
      "value": 1280
    },
    "class_type": "INTConstant",
    "_meta": {
      "title": "Height Upscale"
    }
  },
  "97": {
    "inputs": {
      "model_name": "RealESRGAN_x2.pth"
    },
    "class_type": "UpscaleModelLoader",
    "_meta": {
      "title": "Load Upscale Model"
    }
  },
  "104": {
    "inputs": {
      "width_upscale": [
        "90",
        0
      ],
      "height_upscale": [
        "91",
        0
      ],
      "width": [
        "90",
        0
      ],
      "height": [
        "91",
        0
      ],
      "length": 181,
      "pad_mask_limit": 64,
      "crossfade_frame": 16,
      "loopback_crossfade": 0,
      "crop_ref": false,
      "ref_as_init_frame": true,
      "color_match": true,
      "color_ref": "reference_image",
      "noise_aug": 0.15,
      "seed": 1027767355252118,
      "steps": 4,
      "cfg": 2.5,
      "sampler_name": "res_2m_ode",
      "scheduler": "bong_tangent",
      "denoise": 0.95,
      "model": [
        "60",
        0
      ],
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "vae": [
        "13",
        0
      ],
      "input_video": [
        "116",
        0
      ],
      "croparea_list": [
        "118",
        0
      ],
      "reference_image": [
        "112",
        0
      ],
      "control_video": [
        "116",
        0
      ],
      "nag_params": [
        "109",
        0
      ]
    },
    "class_type": "SuperUltimateVACEUpscale",
    "_meta": {
      "title": "SuperUltimate VACE Upscale"
    }
  },
  "106": {
    "inputs": {
      "unet_name": "Wan2.2_T2V_Low_Noise_14B_VACE-Q8_0.gguf",
      "device": "cuda:0",
      "virtual_vram_gb": 24,
      "use_other_vram": false,
      "expert_mode_allocations": ""
    },
    "class_type": "UnetLoaderGGUFDisTorchMultiGPU",
    "_meta": {
      "title": "UnetLoaderGGUFDisTorchMultiGPU"
    }
  },
  "107": {
    "inputs": {
      "lora_name": "split_files/loras/wan2.2_t2v_lightx2v_4steps_lora_v1.1_low_noise.safetensors",
      "strength_model": 0.8,
      "model": [
        "106",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "108": {
    "inputs": {
      "backend": "inductor",
      "fullgraph": false,
      "mode": "max-autotune-no-cudagraphs",
      "dynamic": false,
      "compile_transformer_blocks_only": true,
      "dynamo_cache_size_limit": 64,
      "model": [
        "111",
        0
      ]
    },
    "class_type": "TorchCompileModelWanVideoV2",
    "_meta": {
      "title": "TorchCompileModelWanVideoV2"
    }
  },
  "109": {
    "inputs": {
      "nag_scale": 5,
      "nag_tau": 2,
      "nag_alpha": 0.25,
      "nag_sigma_end": 0
    },
    "class_type": "NAGParamtersSetting",
    "_meta": {
      "title": "NAG Paramters Setting"
    }
  },
  "111": {
    "inputs": {
      "lora_name": "xxta-maya-clothed-000132.safetensors",
      "strength_model": 1,
      "model": [
        "107",
        0
      ]
    },
    "class_type": "LoraLoaderModelOnly",
    "_meta": {
      "title": "LoraLoaderModelOnly"
    }
  },
  "112": {
    "inputs": {
      "width": [
        "90",
        0
      ],
      "height": [
        "91",
        0
      ],
      "upscale_method": "lanczos",
      "keep_proportion": "stretch",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 2,
      "device": "cpu",
      "image": [
        "24",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "113": {
    "inputs": {
      "model": "u2net: general purpose",
      "providers": "CUDA"
    },
    "class_type": "RemBGSession+",
    "_meta": {
      "title": "ğŸ”§ RemBG Session"
    }
  },
  "114": {
    "inputs": {
      "rembg_session": [
        "113",
        0
      ],
      "image": [
        "115",
        0
      ]
    },
    "class_type": "ImageRemoveBackground+",
    "_meta": {
      "title": "ğŸ”§ Image Remove Background"
    }
  },
  "115": {
    "inputs": {
      "width": [
        "90",
        0
      ],
      "height": [
        "91",
        0
      ],
      "upscale_method": "lanczos",
      "keep_proportion": "stretch",
      "pad_color": "0, 0, 0",
      "crop_position": "center",
      "divisible_by": 2,
      "device": "cpu",
      "image": [
        "17",
        0
      ]
    },
    "class_type": "ImageResizeKJv2",
    "_meta": {
      "title": "Resize Image v2"
    }
  },
  "116": {
    "inputs": {
      "detect_hand": "enable",
      "detect_body": "enable",
      "detect_face": "enable",
      "resolution": [
        "90",
        0
      ],
      "bbox_detector": "yolo_nas_l_fp16.onnx",
      "pose_estimator": "dw-ll_ucoco_384_bs5.torchscript.pt",
      "scale_stick_for_xinsr_cn": "disable",
      "image": [
        "114",
        0
      ]
    },
    "class_type": "DWPreprocessor",
    "_meta": {
      "title": "DWPose Estimator"
    }
  },
  "117": {
    "inputs": {
      "mode": "subtract",
      "foreground_opacity": 1,
      "foreground_scale": 1,
      "position_x": 50,
      "position_y": 50,
      "foreground": [
        "80",
        0
      ],
      "background": [
        "116",
        0
      ]
    },
    "class_type": "AILab_ImageCombiner",
    "_meta": {
      "title": "Image Combiner (RMBG) ğŸ–¼ï¸"
    }
  },
  "118": {
    "inputs": {
      "width_upscale": [
        "90",
        0
      ],
      "height_upscale": [
        "91",
        0
      ],
      "presets": "'ä¸‰' for long narrow screen"
    },
    "class_type": "CustomCropArea",
    "_meta": {
      "title": "Custom Crop Area"
    }
  },
  "120": {
    "inputs": {
      "mode": "always",
      "volume": 1,
      "file": "notify.mp3",
      "any": [
        "104",
        0
      ]
    },
    "class_type": "PlaySound|pysssss",
    "_meta": {
      "title": "PlaySound ğŸ"
    }
  },
  "121": {
    "inputs": {
      "rel_l1_thresh": 0.15,
      "start_percent": 0.1,
      "end_percent": 1,
      "cache_device": "main_device",
      "coefficients": "14B",
      "model": [
        "108",
        0
      ]
    },
    "class_type": "WanVideoTeaCacheKJ",
    "_meta": {
      "title": "WanVideo Tea Cache (native)"
    }
  }
}